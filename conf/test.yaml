hydra:
  run:
    dir: ./

RL:
  algorithm: PPO  # RecurrentPPO, PPO
  policy_network: CnnPolicy # MlpLstmPolicy, MlpPolicy
  settings: DEMO
  save_dir: outputs/logs
  save_freq: 50000
  pretrain_model_path: Training/Logs/PPO_Contact_AMB/model_1500000_steps.zip
  mode: test

action:
  action_num: 13
  trans_step: 0.0015
  rotate_step: 0.2617993877991494 # np.pi/12

state:
  input_type: TTS # {TTS, TTA}
  short_mem_size: 20
  max_novel_size: 300
  grid_size: 10

reward:
  type: AMB # {AMB (AM + 1/sqrt(Number of visits)), AM(area and movement)}
  area_regularizer: 0.1
  visited_state_penalty: -0.15
  novelty_threshold: 3
  no_touch_threshold: 25

termination:
  horizon_length: 5000

environment:
  object:
    object_name: "Strawberry"
    urdf_path: ["objects/ycb/YcbStrawberry/model.urdf"] 
  pose:
    base_position: [ 0, 0, 0.10 ]
    base_orientation: [ 0.0, 0.0, 0, 1 ]
    global_scaling: 1

tacto:
  width: 60
  height: 80
  visualize_gui: False
  background: conf/D20816.png

digit:
  urdf_path: "misc/meshes/digit.urdf"  
  # quaternion from p.getQuaternionFromEuler([0, 0, pi])
  base_orientation: [ 0.0, 0.0, 1.0, 6.123233995736766e-17 ]

pybullet_camera:
  cameraDistance: 0.15
  cameraYaw: 25
  cameraPitch: -25
  cameraTargetPosition: [ 0, 0, 0.12 ]

### Drill
#pybullet_camera:
#  cameraDistance: 0.22
#  cameraYaw: 25
#  cameraPitch: -30
#  cameraTargetPosition: [ 0, 0, 0.2 ]
#

### Banana
#pybullet_camera:
#  cameraDistance: 0.23
#  cameraYaw: 25
#  cameraPitch: -40
#  cameraTargetPosition: [ 0, 0, 0.07 ]

visualization:
  realtime: False
  render: True

