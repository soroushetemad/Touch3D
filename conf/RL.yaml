hydra:
  run:
    dir: ./

RL:
  algorithm: PPO
  policy_network: CnnPolicy # MlpPolicy
  learning_rate = 0.0001 # default: 0.0003
  save_dir: PPO_Contact_AMB
  save_freq: 50000
  pretrain_model_path: 
  mode: train
  ppo_params:
    ent_coef: 0.01
    # n_steps: 2048
    # batch_size: 64
    # n_epochs: 10
    # gamma: 0.99
    # gae_lambda: 0.95

action:
  action_num: 13
  trans_step: 0.0015
  rotate_step: 0.2617993877991494 # np.pi/12

state:
  input_type: TTS #  {TTS, TTA}
  short_mem_size: 20
  max_novel_size: 300
  grid_size: 10

reward:
  type: AMB # {AMB (AM + 1/sqrt(Number of visits)), AM(area and movement)}
  area_regularizer: 0.1
  visited_state_penalty: -0.15
  novelty_threshold: 3
  no_touch_threshold: 25

termination:
  horizon_length: 5000

environment:
  object:
    urdf_path: ["objects/sphere_small.urdf","objects/cube_small.urdf","objects/cylinder.urdf","objects/pyramid.urdf"] 
  #    scaled: True # Has the URDF scale alread been applied?
  #    scale : [[0.06, 0.06, 0.06], [.10, .05, .10]]
  pose:
    base_position: [ 0, 0, 0.1 ]
    base_orientation: [ 0.0, 0.0, 0, 1 ]
    global_scaling: 1

tacto:
  width: 60
  height: 80
  visualize_gui: False
  background: conf/D20816.png

digit:
  urdf_path: "misc/meshes/digit.urdf"
  # quaternion from p.getQuaternionFromEuler([0, 0, pi])
  base_orientation: [ 0.0, 0.0, 1.0, 6.123233995736766e-17 ]

pybullet_camera:
  cameraDistance: 0.15
  cameraYaw: 25
  cameraPitch: -25
  cameraTargetPosition: [ 0, 0, 0.12 ]

visualization:
  realtime: False
  render: True